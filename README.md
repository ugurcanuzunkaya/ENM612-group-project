# Max-Min Separability Projesi

Bu proje, Adil Hoca'nÄ±n makalesinde Ã¶nerilen **Max-Min Separability** algoritmasÄ±nÄ±n Python ile implementasyonunu iÃ§erir. Proje, **Test Driven Development (TDD)** prensiplerine sadÄ±k kalÄ±narak geliÅŸtirilmiÅŸ ve optimizasyon sÃ¼reÃ§leri iÃ§in **Gurobi** Ã§Ã¶zÃ¼cÃ¼sÃ¼ kullanÄ±lmÄ±ÅŸtÄ±r.

## ğŸ“‹ Ä°Ã§indekiler
- [Proje HakkÄ±nda](#proje-hakkÄ±nda)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [Proje YapÄ±sÄ±](#proje-yapÄ±sÄ±)
- [Algoritma DetaylarÄ±](#algoritma-detaylarÄ±)
- [SonuÃ§larÄ±n Analizi](#sonuÃ§larÄ±n-analizi)
- [Gelecek Ã‡alÄ±ÅŸmalar](#gelecek-Ã§alÄ±ÅŸmalar)

## ğŸš€ Proje HakkÄ±nda
Bu Ã§alÄ±ÅŸma, lineer olmayan veri setlerini (Ã¶rneÄŸin `make_moons`) ayÄ±rmak iÃ§in parÃ§alÄ± lineer (piecewise linear) hiperdÃ¼zlemler kullanan bir sÄ±nÄ±flandÄ±rma yÃ¶ntemidir. YÃ¶ntem, klasik SVM veya Lojistik Regresyon'dan farklÄ± olarak, her sÄ±nÄ±f iÃ§in birden fazla hiperdÃ¼zlem grubu (polyhedral sets) tanÄ±mlar ve **Max-Min** mantÄ±ÄŸÄ±yla en iyi ayrÄ±mÄ± yapmaya Ã§alÄ±ÅŸÄ±r.

TÃ¼revsiz optimizasyon (Derivative-Free Optimization) yÃ¶ntemlerinden biri olan **Discrete Gradient Method (DGM)** kullanÄ±lmÄ±ÅŸtÄ±r. Ä°niÅŸ yÃ¶nÃ¼nÃ¼ bulmak iÃ§in ise Gurobi ile bir Kuadratik Programlama (QP) alt problemi Ã§Ã¶zÃ¼lmektedir.

## ğŸ›  Kurulum

Bu projeyi Ã§alÄ±ÅŸtÄ±rmak iÃ§in sisteminizde Python ve Gurobi lisansÄ±nÄ±n yÃ¼klÃ¼ olmasÄ± gerekir. Proje baÄŸÄ±mlÄ±lÄ±klarÄ± `uv` paket yÃ¶neticisi ile yÃ¶netilmektedir.

### AdÄ±m 1: Projeyi KlonlayÄ±n
```bash
git clone <repo-url>
cd ENM612-group-project
```

### AdÄ±m 2: BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin
EÄŸer `uv` yÃ¼klÃ¼ deÄŸilse, Ã¶nce onu yÃ¼kleyin veya standart `pip` kullanÄ±n.
```bash
# uv ile kurulum (Ã–nerilen)
uv sync

# Veya pip ile
pip install numpy matplotlib gurobipy scikit-learn
```

**Ã–nemli Not:** Gurobi lisansÄ±nÄ±zÄ±n versiyonu ile `gurobipy` kÃ¼tÃ¼phanesinin versiyonunun uyumlu olduÄŸundan emin olun. (Bu projede 12.0.3 versiyonu kullanÄ±lmÄ±ÅŸtÄ±r).

## ğŸ’» KullanÄ±m

### Testleri Ã‡alÄ±ÅŸtÄ±rma (TDD)
Kodun doÄŸruluÄŸunu teyit etmek iÃ§in birim testleri Ã§alÄ±ÅŸtÄ±rabilirsiniz:
```bash
uv run pytest tests/test_max_min.py
```
Bu testler; hiperparametrelerin doÄŸruluÄŸunu, kayÄ±p fonksiyonunun negatif olmamasÄ±nÄ± ve gradyan boyutlarÄ±nÄ± kontrol eder.

### Modeli EÄŸitme ve GÃ¶rselleÅŸtirme
Modeli farklÄ± veri setleri Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmak iÃ§in CLI argÃ¼manlarÄ± eklenmiÅŸtir.

**Moons Veri Seti (VarsayÄ±lan):**
```bash
uv run main.py --dataset moons --groups 3 --planes 2
```

**Breast Cancer Veri Seti:**
```bash
uv run main.py --dataset breast_cancer
```

**Blobs 3D Veri Seti (3D GÃ¶rselleÅŸtirme Testi):**
```bash
uv run main.py --dataset blobs_3d --groups 3 --planes 2
```

**Ã–zel (Custom) Veri Seti:**
1. `src/dataset_loader.py` dosyasÄ±ndaki `load_custom_dataset` fonksiyonunu dÃ¼zenleyin.
2. AÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
uv run main.py --dataset custom
```

Bu komutlar eÄŸitimi baÅŸlatacak, baÅŸarÄ± oranlarÄ±nÄ± (Accuracy, F1-Score) ve toplam sÃ¼reyi raporlayacaktÄ±r. 2 boyutlu veri setleri iÃ§in `decision_boundary.png` gÃ¶rseli oluÅŸturulur.

## ğŸ“‚ Proje YapÄ±sÄ±

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ max_min.py       # AlgoritmanÄ±n ana sÄ±nÄ±fÄ± (MaxMinSeparability)
â”‚   â”œâ”€â”€ dataset_loader.py # Veri seti yÃ¼kleme ve iÅŸleme modÃ¼lÃ¼
â”‚   â””â”€â”€ visualization.py  # GÃ¶rselleÅŸtirme modÃ¼lÃ¼ (2D/3D)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_max_min.py  # Birim testler
â”œâ”€â”€ main.py              # Ã‡alÄ±ÅŸtÄ±rma ve gÃ¶rselleÅŸtirme betiÄŸi
â”œâ”€â”€ pyproject.toml       # BaÄŸÄ±mlÄ±lÄ±k dosyasÄ±
â””â”€â”€ README.md            # DokÃ¼mantasyon
```

## ğŸ§  Algoritma DetaylarÄ±

Kodun temel bileÅŸenleri ÅŸunlardÄ±r:

1.  **Objective Function (AmaÃ§ Fonksiyonu):** Makaledeki Denklem 31 ve 32'nin vektÃ¶rize edilmiÅŸ halidir. Hata (Loss) deÄŸeri hesaplanÄ±rken, doÄŸru sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ ve "gÃ¼venli" bÃ¶lgedeki noktalar iÃ§in hata 0 kabul edilir (Hinge Loss benzeri yapÄ±).
2.  **Discrete Gradient (AyrÄ±k Gradyan):** Fonksiyonun tÃ¼revi alÄ±namadÄ±ÄŸÄ± iÃ§in (non-smooth), rastgele yÃ¶nlerdeki deÄŸiÅŸimlere bakÄ±larak gradyan tahmin edilir (TanÄ±m 2).
3.  **Direction Finding (YÃ¶n Bulma):** Elde edilen gradyan demetinin (bundle) konveks zarfÄ±nda orijine en yakÄ±n nokta bulunur. Bu nokta, en dik iniÅŸ yÃ¶nÃ¼nÃ¼n tersidir. Bu iÅŸlem Gurobi ile Ã§Ã¶zÃ¼lÃ¼r.

## ğŸ“Š SonuÃ§larÄ±n Analizi

`main.py` Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda sonuÃ§lar `results/` klasÃ¶rÃ¼ne kaydedilir:
- **`{dataset}_results.txt`**: Modelin aÄŸÄ±rlÄ±klarÄ±, biases deÄŸerleri ve baÅŸarÄ±m metrikleri.
- **`{dataset}_decision_boundary_2d.png`**: 2D veri setleri iÃ§in karar sÄ±nÄ±rlarÄ±.
- **`{dataset}_decision_boundary_3d.png`**: 3D veri setleri iÃ§in 3 boyutlu daÄŸÄ±lÄ±m.

Ã–rnek BaÅŸarÄ±mlar:
- **Moons:** ~98.5% DoÄŸruluk
- **Breast Cancer:** ~98.9% DoÄŸruluk
- **Blobs 3D:** ~100% DoÄŸruluk

2 boyutlu veri setleri iÃ§in oluÅŸturulan gÃ¶rsel ÅŸunlarÄ± gÃ¶sterir:
- **Mavi Noktalar:** A SÄ±nÄ±fÄ± (Min Region)
- **KÄ±rmÄ±zÄ± Noktalar:** B SÄ±nÄ±fÄ± (Max Region)
- **Kontur AlanlarÄ±:** Modelin karar sÄ±nÄ±rlarÄ±.

Model, `make_moons` gibi lineer ayrÄ±lamayan bir veri setini, birden fazla doÄŸru parÃ§asÄ± kullanarak baÅŸarÄ±yla ayÄ±rmaktadÄ±r. BaÅŸlangÄ±Ã§ta yÃ¼ksek olan hata deÄŸeri (Loss), iterasyonlar ilerledikÃ§e azalmakta ve 0'a yaklaÅŸmaktadÄ±r. Bu, algoritmanÄ±n yakÄ±nsadÄ±ÄŸÄ±nÄ± gÃ¶sterir.


---
*Bu proje ENM612 dersi kapsamÄ±nda hazÄ±rlanmÄ±ÅŸtÄ±r.*
